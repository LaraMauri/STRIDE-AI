# ML Model Assets and their Failure Modes

|ML model asset|Answers to FMEA asset questions|FMEA failure modes<br />(Answers to FMEA function questions)|
|:---|:---|:--|
|**_Hyper-parameters_** (HPs) are meta parameters associated with any AI-ML algorithm that do not have dependency on the input data, and whose value is set before the learning process begins. They are defined by trial-and-error using model space search techniques.|- HPs are used for model-space search and identification of the best AI-ML model.<br />- Their value defines the training and structure of the AI-ML model.<br />- HPs should not change during training.|- Hyper-parameters may fail to deliver the size and configuration for the model that makes its training and operation feasible.<br />- HPs may be used as fitting knobs, e.g. tampering with them to make the model over-fitted to specific training data.|
|**_Model parameters_** are variables that are internal to the model (e.g., the weights in a NN, or the centroids in a clustering algorithms) and whose value can be computed by fitting the given input data to the model.|- Parameters determine the inferences (i.e. the actual outputs) computed by the AI-ML model.<br />- Parameters should not reveal information about the training data or the HPs.|- Parameters fail when the AI-ML model’s output computed according to them is such that the model’s performance in executing the task (classification, prediction, anomaly detection) is poor.<br />- Parameters can be used as covert channels to encode hidden information in the inferences.|
|**_Data pre-processing algorithms_** are techniques employed to improve information quality by cleaning, integrating and transforming data.|- Data pre-processing has the purpose to convert incomplete or defective raw data into improved training data to provide improved ML model’s performance.<br />- The data pre-processing algorithm should not degrade raw data value.<br />- Data pre-processing should not harvest information about the data statistics.|- Data pre-processing algorithms fail when errors in the definition of the data conversion generate flawed or defective training data.<br />- Data pre-processing may be used to achieve other data properties (e.g., anonymity).|
|**_Trained models_** are AI-ML supervisioned models whose internal parameters have been adjusted by training to achieve a minimum of the error function that defines the distance between actual and expected outputs.|- Trained models perform a task (like regression, prediction or anomaly detection) computing inferences on test input data.|- Trained models fail when the discrepancy between the training data seen during the learning process and inference is so high to cause a drop in performance in production.|
|**_Deployed models_** are AI-ML supervisioned models whose parameters are assumed to be stable, and to which users can submit inputs and receive inference outputs.|- Deployed models perform a task (like regression, prediction or anomaly detection) computing inferences in production.|- Deployed models fail when the AI-ML task is not performed at the desired performance (e.g. accuracy) level.<br />- Deployed models can be doctored to compute inferences aimed to benefit malicious third parties.|
