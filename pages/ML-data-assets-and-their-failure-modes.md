# ML Assets and their Failure Modes

- [Data](https://github.com/LaraMauri/STRIDE-AI/blob/main/pages/ML-data-assets-and-their-failure-modes.md#data)
- [Models](https://github.com/LaraMauri/STRIDE-AI/blob/main/pages/ML-data-assets-and-their-failure-modes.md#models)
- [Artefacts](https://github.com/LaraMauri/STRIDE-AI/blob/main/pages/ML-data-assets-and-their-failure-modes.md#artefacts)

## Data

|ML Data Asset|Answers to [FMEA Asset Questions](https://github.com/LaraMauri/STRIDE-AI/blob/main/pages/failure-mode-and-effects-analysis-of-AI-ML-systems.md#functions)|FMEA Failure Modes<br />(Answers to [FMEA Function Questions](https://github.com/LaraMauri/STRIDE-AI/blob/main/pages/failure-mode-and-effects-analysis-of-AI-ML-systems.md#failure-modes))|
|:---|:---|:---|
|**_Functional requirements_** model the domain of interest, the problem to be solved, and the task to be executed by the ML model. **_Non-functional requirements_** identify architectural (hardware) and code (software) needs.|<ul><li> Requirements serve to reach a clear understanding of the business context. </li><li> Requirements must articulate a definition of the business goals to be achieved along with the data required to achieve them. </li><li> Requirements must not identity an improper model type to be used in the AI system. </li><li> Requirements must not use a metrics not suitable to assess the degree to which the goals have been achieved. </li></ul> | <ul><li> Unclear requirements may lead to poorly accurate AI-ML models. </li><li> Requirements may not take into account the adverse effect of non-functional properties mandated by regulations. </li><li> Requirements may underestimate the severity of information leaks. </li></ul>|
|**_Raw data_** refers to any type of information gathered at the data management stage, before it is transformed or analyzed in any way.| <ul><li> Raw data constitute the primary source of information needed to achieve the business goals. </li><li> Raw data serve to create an initial data set (not yet ready for analysis) for use in the subsequent stages of the AI life-cycle. </li></ul> | <ul><li> Raw data may not be sufficiently representative of the domain or unfit the AI-ML model business goal (e.g. due to sample size and population characteristics). </li><li> A large volume of raw data does not always imply representativeness: if data selection is biased towards some elements that have similar characteristics (a phenomenon called selection bias) then even a large data set will not be representative enough. </li></ul> |
|**_Pre-processed data_** refers to raw data being transformed (cleaned, organized) so as it is ready to be used by an AI-ML model| <ul><li> Pre-processed data create a data set suitable for effective statistical analyses. </li></ul> | <ul><li> Pre-processed data may cause incorrect estimates of ML models’ performance when data preparation is applied before splitting the data for model evaluation. </li><li> Performing pre-processing on the entire data set may result in data leakage, where information about test or validation data set is made available to the model in the training data set. </li></ul> |
|**_Labeled data_** refers to sets of scalar or multi-dimensional data items used at the model learning stage. This data is tagged with informative labels, for the purpose of training a supervised ML model. | <ul><li> Labels make data useful in supervised ML setups. </li><li> ML algorithms may use initial labeled data to work with additional unlabeled data. </li></ul> | <ul><li> Labeled data fail when enough items are deleted or omitted, a sufficient number of spurious labelled data is included into the data set, or enough labels are modified. </li><li> Labeled data may cause a classifier to deviate from its expected behavior. </li></ul> |
|**_Validation data_** is also used at the model learning stage, but differs from ordinary labeled data in usage and, usually, in collection circumstances. Validation data sets are mostly used to perform an evaluation of the ML model in-training, e.g. by stopping training (early stopping) when the error on the validation set increases too much, as this is considered a sign of over-fitting.| <ul><li> Validation data provide an unbiased evaluation of a model fit on the training data set while tuning the hyper-parameters. </li><li> Validation data help to deal with issues like over-fitting. </li></ul> | <ul><li> Validation data may fail when labelled data items are manipulated. </li><li> If modified, validation data items can affect how the error computed on the validation data set fluctuates during training. </li><li> Even a single modification on the validation set may be enough for introducing a spurious error increase that could cut short the training. </li></ul> |
|**_Augmented data_** is labeled data that is complemented at the model tuning stage by additional data produced by transformations or by generative ML models. Augmentation increases labeled data sets’ diversity, which is supposed to prevent over-fitting.| <ul><li> Augmented data help to solve the problem of data deficiency by increasing the amount of data available in the training data set. </li><li> Data augmentation can be performed in data-space or feature-space. </li><li> Augmented data are supposed to prevent over-fitting. </li></ul> | <ul><li> Augmented data sets may fail due to inconsistency with the training set they are derived from. </li><li> Heuristic data augmentation schemes are often tuned manually by humans, and defective augmentation policies may cause ML models to loose rather than gaining accuracy from the augmented data. </li></ul> |
|**_Held-out test cases_** (HTCs) are inputs used to test ML models in production, i.e. in the model maintenance stage. HTCs include special inputs of high interest for the application.| <ul><li> The rationale for HTCs is that even if an ML model keeps showing good accuracy, its performance on specific inputs may become unacceptable. </li></ul> | <ul><li> HTCs fail when the ML model’s accuracy metrics computed on them does not correspond to the business goals of the application. </li><li> Careless selection of HTCs can trigger unneeded model retraining. </li></ul> |
|**_Inferences_** are results computed by ML models based on real inputs, according to the task of interest in the model deployment and model maintenance stages.| <ul><li> Inferences serve to produce actionable outputs when live data run into ML models. </li></ul> | <ul><li> Inferences may fail by showing high entropy, i.e. conveying little information useful for the ML task at hand. </li></ul>|

## Models

|ML Model Asset|Answers to [FMEA Asset Questions](https://github.com/LaraMauri/STRIDE-AI/blob/main/pages/failure-mode-and-effects-analysis-of-AI-ML-systems.md#functions)|FMEA Failure Modes<br />(Answers to [FMEA Function Questions](https://github.com/LaraMauri/STRIDE-AI/blob/main/pages/failure-mode-and-effects-analysis-of-AI-ML-systems.md#failure-modes))|
|:---|:---|:--|
|**_Hyper-parameters_** (HPs) are meta parameters associated with any AI-ML algorithm that do not have dependency on the input data, and whose value is set before the learning process begins. They are defined by trial-and-error using model space search techniques.|- HPs are used for model-space search and identification of the best AI-ML model.<br />- Their value defines the training and structure of the AI-ML model.<br />- HPs should not change during training.|- HPs may fail to deliver the size and configuration for the model that makes its training and operation feasible.<br />- HPs may be used as fitting knobs, e.g. tampering with them to make the model over-fitted to specific training data.|
|**_Model parameters_** are variables that are internal to the model (e.g., the weights in a NN, or the centroids in a clustering algorithms) and whose value can be computed by fitting the given input data to the model.|- Parameters determine the inferences (i.e. the actual outputs) computed by the AI-ML model.<br />- Parameters should not reveal information about the training data or the HPs.|- Parameters fail when the AI-ML model’s output computed according to them is such that the model’s performance in executing the task (classification, prediction, anomaly detection) is poor.<br />- Parameters can be used as covert channels to encode hidden information in the inferences.|
|**_Data pre-processing algorithms_** are techniques employed to improve information quality by cleaning, integrating and transforming data.|- Data pre-processing has the purpose to convert incomplete or defective raw data into improved training data to provide improved AI-ML model’s performance.<br />- The data pre-processing algorithm should not degrade raw data value.<br />- Data pre-processing should not harvest information about the data statistics.|- Data pre-processing algorithms fail when errors in the definition of the data conversion generate flawed or defective training data.<br />- Data pre-processing may be used to achieve other data properties (e.g., anonymity).|
|**_Trained models_** are AI-ML supervisioned models whose internal parameters have been adjusted by training to achieve a minimum of the error function that defines the distance between actual and expected outputs.|- Trained models perform a task (like regression, prediction or anomaly detection) computing inferences on test input data.|- Trained models fail when the discrepancy between the training data seen during the learning process and inference is so high to cause a drop in performance in production.|
|**_Deployed models_** are AI-ML supervisioned models whose parameters are assumed to be stable, and to which users can submit inputs and receive inference outputs.|- Deployed models perform a task (like regression, prediction or anomaly detection) computing inferences in production.|- Deployed models fail when the AI-ML task is not performed at the desired performance (e.g. accuracy) level.<br />- Deployed models can be doctored to compute inferences aimed to benefit malicious third parties.|





## Artefacts



